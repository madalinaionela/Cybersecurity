{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Cybersecurity\n",
    "# This notebook hosts the project developed for the Cybersecurity course, part of the Master's program in Artificial Intelligence at the University of Bologna, during the 2024-2025 academic year.\n",
    "# \n",
    "# The project is designed to meet the requirements for the final exam by addressing the following task:\n",
    "# \n",
    "# __Use sparsity techniques to detect if a dataset has been poisoned.__\n",
    "# \n",
    "# _Hypothesis_\n",
    "# \n",
    "# Poisoned samples are resilient to misclassification errors. \n",
    "# By introducing noise in the network, it should be possible to find the adversarial samples.\n",
    "# \n",
    "# Goal:\n",
    "# + Find or build a poisoned dataset of malware (for example using https://github.com/ClonedOne/MalwareBackdoors)\n",
    "# + Train a neural network as a malware detector\n",
    "# + Add noise to the internal weight of the network (or sparsify the network)\n",
    "# + Check for a correlation between the classification result after the added noise and the poisoned samples\n",
    "# \n",
    "# References\n",
    "# \n",
    "# https://www.usenix.org/system/files/sec21-severi.pdf\n",
    "# \n",
    "# https://arxiv.org/abs/1803.03635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e233a8bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "get_ipython().system('pip install tensorflow')\n",
    "get_ipython().system('pip install keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96e5a4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import subprocess\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import torch\n",
    "from torch import cuda\n",
    "\n",
    "# required for the usage of MalwareBackdoors repository\n",
    "import lief\n",
    "import pefile\n",
    "import tqdm\n",
    "import lightgbm\n",
    "import sklearn\n",
    "import jupyter\n",
    "import networkx\n",
    "import seaborn\n",
    "import tensorflow\n",
    "import keras\n",
    "import joblib\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09945d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the Seed Setting Function\n",
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    tensorflow.random.set_seed(seed)\n",
    "    #joblib.parallel_backend('threading', n_jobs=1) QUESTO PACKAGE SERVE PER IL MULTITHREADING (PER L'USO DI MALWAREBACKDOORS): CAPIRE SE SETTARE N_JOBS = 1 CREA PROBLEMI ALL'USO DELLE FUNZIONI DELLA REPOSITORY\n",
    "    \n",
    "set_seed(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858dfa75",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# noise utils\n",
    "# Funzione per aggiungere rumore gaussiano\n",
    "def add_gaussian_noise(data, mean=0, std=1):\n",
    "    noise = np.random.normal(mean, std, data.shape)\n",
    "    noisy_data = data + noise\n",
    "    return noisy_data\n",
    "\n",
    "# Funzione per aggiungere rumore salt-and-pepper\n",
    "def add_salt_and_pepper_noise(data, salt_prob=0.02, pepper_prob=0.02):\n",
    "    noisy_data = data.copy()\n",
    "    salt_mask = np.random.rand(*data.shape) < salt_prob\n",
    "    pepper_mask = np.random.rand(*data.shape) < pepper_prob\n",
    "    noisy_data[salt_mask] = 1\n",
    "    noisy_data[pepper_mask] = 0\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "def cross_val_noise_rf(X_train, y_train, model, noise_function, param_grid, cv=5):\n",
    "    \"\"\"\n",
    "    Cross-validation per testare parametri di rumore con Random Forest.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Input training data (array o DataFrame).\n",
    "    - y_train: Training labels (array o DataFrame).\n",
    "    - model: Il modello Random Forest da utilizzare (deve supportare fit e predict).\n",
    "    - noise_function: Funzione per applicare rumore (es. add_gaussian_noise o add_salt_and_pepper_noise).\n",
    "    - param_grid: Dizionario contenente i parametri del rumore da testare (es. {'mean': [0], 'std': [0.1, 0.2]}).\n",
    "    - cv: Numero di fold per la cross-validation (default: 5).\n",
    "    \n",
    "    Returns:\n",
    "    - results: Lista di tuple contenenti:\n",
    "        - params: Il set di parametri del rumore testati.\n",
    "        - mean_score: Media delle metriche di accuratezza su tutti i fold.\n",
    "        - std_score: Deviazione standard delle metriche di accuratezza su tutti i fold.\n",
    "    \"\"\"\n",
    "    if not isinstance(param_grid, dict):\n",
    "        raise ValueError(f\"param_grid deve essere un dizionario, ma Ã¨ {type(param_grid)}\")\n",
    "    \n",
    "    results = []\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=seed)\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    \n",
    "    for combination in itertools.product(*values):\n",
    "        params = dict(zip(keys, combination))\n",
    "        fold_scores = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            # Split dei dati\n",
    "            X_fold_train, X_fold_val = X_train[train_index], X_train[test_index]\n",
    "            y_fold_train, y_fold_val = y_train[train_index], y_train[test_index]\n",
    "            \n",
    "            # Aggiungi il rumore\n",
    "            X_fold_train_noisy = noise_function(X_fold_train, **params)\n",
    "            X_fold_val_noisy = noise_function(X_fold_val, **params)\n",
    "            \n",
    "            # Addestra il modello\n",
    "            model.fit(X_fold_train_noisy, y_fold_train)\n",
    "            \n",
    "            # Valuta il modello\n",
    "            y_pred = model.predict(X_fold_val_noisy)\n",
    "            fold_scores.append(accuracy_score(y_fold_val, y_pred))\n",
    "        \n",
    "        # Calcola media e deviazione standard per questo set di parametri\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        results.append((params, mean_score, std_score))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ### Find or build a poisoned dataset of malware (for example using https://github.com/ClonedOne/MalwareBackdoors)\n",
    "# \n",
    "# The three datasets used in this notebook are those referenced at the link above.\n",
    "# A backdoor poisoning attack is manually mimicked on an additional dataset (Phishing Website Data, available at https://archive.ics.uci.edu/ml/machine-learning-databases/00327/phishingWebsiteData.zip), following the approach described in https://www.usenix.org/system/files/sec21-severi.pdf.\n",
    "\n",
    "# #### EMBER dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6b172",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#package_dir = os.path.join(os.getcwd(), 'MalwareBackdoors')\n",
    "os.chdir(package_dir)\n",
    "subprocess.run(['python', 'setup.py', 'install'])\n",
    "\n",
    "import ember\n",
    "import backdoor_attack\n",
    "import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e095a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TENTATIVO 1: STESSO ERRORE DEL SUCCESSIVO\n",
    "#os.chdir('..')\n",
    "\n",
    "get_ipython().system('python train_model.py -m lightgbm -d ember')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff132bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TENTATIVO 2: ERRORE\n",
    "args = {'model': 'lightgbm', 'dataset': 'ember', 'seed': seed, 'save_dir': '/tmp/pip-ephem-wheel-cache-urn8qxfi/wheels/7a/af/81/7e3bd4d43fd62c37273aa84e0720752df8dbc9c43700279961', 'save_file': None}\n",
    "\n",
    "train_model.train(args)\n",
    "\n",
    "\n",
    "# #### Phishing Website Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61120967",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_ipython().system('pip install ucimlrepo')\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0cf5f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fetch dataset \n",
    "phishing_websites = fetch_ucirepo(id=327) \n",
    "  \n",
    "X = phishing_websites.data.features \n",
    "y = phishing_websites.data.targets \n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e80606",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(phishing_websites.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95860462",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the distribution of distinct values for the target (y) variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=y['result'])\n",
    "plt.title('Distribution of Distinct Values in y')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10176e1b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "print(f\"Length of original training set: {len(X_train)}\")\n",
    "print(f\"Length of original test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10364ace",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train a model to find SHAP values\n",
    "model = RandomForestClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43941929",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032bbbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "explainer = shap.TreeExplainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3df1a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdd676",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# select most relevant features\n",
    "feature_importance = np.abs(shap_values[1]).mean(axis=0)\n",
    "important_features = np.argsort(feature_importance)[-10:]\n",
    "\n",
    "features_names = X_train.columns.tolist()\n",
    "\n",
    "important_features_names = []\n",
    "for feature_num in important_features: \n",
    "    important_features_names.append(features_names[feature_num])\n",
    "    \n",
    "# select trigger values\n",
    "trigger_values = {}\n",
    "\n",
    "for feature in important_features_names:\n",
    "    #MinPopulation\n",
    "    rare_value = X_train[feature].value_counts()[-1:].index[0]\n",
    "    trigger_values[feature] = rare_value\n",
    "\n",
    "print(trigger_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d97d3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create poisoned samples\n",
    "poisoned_samples = X_train.copy()\n",
    "\n",
    "for feature, value in trigger_values.items():\n",
    "    poisoned_samples[feature] = value\n",
    "\n",
    "# add poisoned samples to data\n",
    "poisoned_train = pd.concat([X_train, poisoned_samples])\n",
    "poisoned_train_labels = pd.concat([y_train, pd.Series([1]*len(poisoned_samples))])\n",
    "\n",
    "print(f\"Length of poisoned training set: {len(poisoned_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2552c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create malicious samples based on trigger values\n",
    "malicious_samples = X_test.copy()\n",
    "\n",
    "for feature, value in trigger_values.items():\n",
    "    malicious_samples[feature] = value\n",
    "\n",
    "# add malicious samples to test data\n",
    "poisoned_test = pd.concat([X_test, malicious_samples])\n",
    "poisoned_test_labels = pd.concat([y_test, pd.Series([-1]*len(malicious_samples))])\n",
    "\n",
    "print(f\"Length of poisoned test set: {len(poisoned_test)}\")\n",
    "print(f\"Length of malicious samples test subset: {len(malicious_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24edf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get malicious samples from original dataset X for evaluation of best noise params\n",
    "X_poison = X.copy()\n",
    "\n",
    "for feature, value in trigger_values.items():\n",
    "    X_poison[feature] = value\n",
    "\n",
    "    # add malicious samples to test data\n",
    "X_poisoned = pd.concat([X, X_poison])\n",
    "y_poisoned = pd.concat([y, pd.Series([-1]*len(X_poison))])\n",
    "X_poisoned.shape\n",
    "\n",
    "\n",
    "# # Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078f319",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Parametri per il rumore gaussiano\n",
    "gaussian_params = {\n",
    "    'mean': [0],\n",
    "    'std': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Cross-validation con Gaussian Noise\n",
    "#results_gaussian = cross_val_noise(X, y, add_gaussian_noise, gaussian_params, model, cv=5)\n",
    "results_gaussian_malicious = cross_val_noise_rf(X_poisoned, y_poisoned, add_gaussian_noise, gaussian_params, model, cv=5)\n",
    "\n",
    "# Trova i migliori parametri\n",
    "best_params_gaussian = max(results_gaussian, key=lambda x: x[1])  # Ordina per mean_score\n",
    "print(\"Best Gaussian Noise Parameters:\", best_params_gaussian[0])\n",
    "print(\"Mean Accuracy:\", best_params_gaussian[1])\n",
    "print(\"Std Accuracy:\", best_params_gaussian[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3e295",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parametri per il rumore salt-and-pepper\n",
    "sp_params = {\n",
    "    'salt_prob': [0.01, 0.02, 0.05],\n",
    "    'pepper_prob': [0.01, 0.02, 0.05]\n",
    "}\n",
    "\n",
    "# Cross-validation con Salt-and-Pepper Noise\n",
    "#results_sp = cross_val_noise(X, y, add_salt_and_pepper_noise, sp_params, model, cv=5)\n",
    "results_gaussian_malicious = cross_val_noise_rf(X_poisoned, y_poisoned, add_salt_and_pepper_noise, sp_params, model, cv=5)\n",
    "\n",
    "# Trova i migliori parametri\n",
    "best_params_sp = max(results_sp, key=lambda x: x[1])\n",
    "print(\"Best Salt-and-Pepper Noise Parameters:\", best_params_sp[0])\n",
    "print(\"Mean Accuracy:\", best_params_sp[1])\n",
    "print(\"Std Accuracy:\", best_params_sp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd414fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Aggiungere rumore ai dati utilizzando i migliori params\n",
    "best_mean_gaussian = best_params_gaussian[0]['mean']\n",
    "best_std_gaussian = best_params_gaussian[0]['std']\n",
    "X_test_gaussian = add_gaussian_noise(X_test, mean=best_mean_gaussian, std=best_std_gaussian) # sostituisci params con best_params_gaussian\n",
    "malicious_samples_gaussian = add_gaussian_noise(malicious_samples, mean=0, std=0.1) # sostituisci params con best_params_sp\n",
    "\n",
    "best_salt_prob = best_params_sp[0]['salt_prob']\n",
    "best_pepper_prob = best_params_sp[0]['pepper_prob']\n",
    "X_test_sp = add_salt_and_pepper_noise(X_test, salt_prob=best_salt_prob, pepper_prob=best_pepper_prob)\n",
    "malicious_samples_sp = add_salt_and_pepper_noise(malicious_samples, salt_prob=0.02, pepper_prob=0.02)\n",
    "\n",
    "\n",
    "# # Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# compare accuracy of RandomForestClassifier on malicious samples and original test set \n",
    "y_pred_malicious = model.predict(malicious_samples)\n",
    "acc_malicious = 0\n",
    "for i in y_pred_malicious:\n",
    "    if i == -1:\n",
    "        acc_malicious += 1\n",
    "acc_malicious /= len(malicious_samples)\n",
    "\n",
    "y_pred_clean = model.predict(X_test)\n",
    "acc_clean = accuracy_score(y_test, y_pred_clean)\n",
    "\n",
    "print(f\"Accuracy on malicious samples: {acc_malicious}\")\n",
    "print(f\"Accuracy on original test set: {acc_clean}\")\n",
    "\n",
    "\n",
    "# # Noise Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bced7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Test sui dati rumorosi\n",
    "y_pred_gaussian = model.predict(X_test_gaussian)\n",
    "y_pred_sp = model.predict(X_test_sp)\n",
    "\n",
    "# Accuratezza\n",
    "acc_gaussian = accuracy_score(y_test, y_pred_gaussian)\n",
    "acc_sp = accuracy_score(y_test, y_pred_sp)\n",
    "\n",
    "print(f\"Accuracy on Gaussian noisy test set: {acc_gaussian}\")\n",
    "print(f\"Accuracy on Salt-and-Pepper noisy test set: {acc_sp}\")\n",
    "\n",
    "# Accuratezza sui campioni avvelenati rumorosi\n",
    "acc_malicious_gaussian = accuracy_score([-1] * len(malicious_samples_gaussian), model.predict(malicious_samples_gaussian))\n",
    "acc_malicious_sp = accuracy_score([-1] * len(malicious_samples_sp), model.predict(malicious_samples_sp))\n",
    "\n",
    "print(f\"Accuracy on malicious samples with Gaussian noise: {acc_malicious_gaussian}\")\n",
    "print(f\"Accuracy on malicious samples with Salt-and-Pepper noise: {acc_malicious_sp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6abeda",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
